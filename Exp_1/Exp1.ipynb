{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度学习 实验1\n",
    "\n",
    "本节课我们尝试实现简单的模型——线性回归，线性回归是最简单的模型\n",
    "\n",
    "$$\n",
    "\\hat y=w\\cdot x+b\n",
    "$$\n",
    "\n",
    "其中 $w,b$ 是需要训练的参数，在训练前，请以分布 $U(-0.1,0.1)$ 进行随机初始化\n",
    "\n",
    "损失函数取\n",
    "\n",
    "$$\n",
    "L=\\frac{1}{2}(\\hat y-y)^2\n",
    "$$\n",
    "\n",
    "使用随机梯度下降法，在每次迭代中随机取样本 $x,y$，按照下式进行迭代：\n",
    "\n",
    "$$\n",
    "w\\leftarrow w-\\eta\\frac{\\partial L}{\\partial w}\n",
    "$$\n",
    "$$\n",
    "b\\leftarrow b-\\eta\\frac{\\partial L}{\\partial b}\n",
    "$$\n",
    "\n",
    "其中学习率 $\\eta$ 请自行调节。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "用代码实现线性回归模型，请不要调用 `sklearn` 等机器学习库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def liner(w, b, x):\n",
    "    return np.dot(w,x) + b\n",
    "def loss(y, y_hat):\n",
    "    return 0.5*((y_hat-y)**2)\n",
    "def optimize(w, b, eta, y_hat,y):\n",
    "    dw = (y_hat-y)*x*eta\n",
    "    db = (y_hat-y)*eta\n",
    "    return w-dw, b-db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "读取数据文件 `train_data.csv` 和 `test_data.csv`，文件中列为 `label` 的表示标签，1 表示正例，0 表示负例，其余列为 $x$，取值均为 0 或 1。使用 `train_data.csv` 训练你的模型，并用 `test_data.csv` 进行测试，计算模型的准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7364341085271318\n"
     ]
    }
   ],
   "source": [
    "eta = 0.0025\n",
    "w = (-1 + 2*np.random.random(100))/10\n",
    "b = (-1 + 2*np.random.random())/10\n",
    "i = 0\n",
    "train_data = pd.read_csv(\"train_data.csv\")\n",
    "for i in range(1000):\n",
    "    x = train_data.sample().values\n",
    "    y = x[0][100]\n",
    "    x = x[0][:100]\n",
    "    y_hat = liner(w, b, x.T)\n",
    "    w, b = optimize(w, b, eta, y_hat, y)\n",
    "test_data = pd.read_csv(\"test_data.csv\")\n",
    "cnt = 0\n",
    "for i in range(258):\n",
    "    x = test_data.loc[i].values[:100]\n",
    "    y = test_data.loc[i].values[100]\n",
    "    y_hat = liner(w, b, x)\n",
    "    if(y_hat>0.5 and y==1):\n",
    "        cnt = cnt + 1\n",
    "    elif(y_hat<0.5 and y==0):\n",
    "        cnt = cnt + 1\n",
    "p = cnt/258\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "请尝试使用不同的学习率 $\\eta$ 进行测试，比较模型的效果，试分析 $\\eta$ 的大小对模型效果的影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\123\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in double_scalars\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\123\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in multiply\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when eta = 0.25, p = 0.0\n",
      "when eta = 0.075, p = 0.9883720930232558\n",
      "when eta = 0.065, p = 0.9922480620155039\n",
      "when eta = 0.06, p = 0.9844961240310077\n",
      "when eta = 0.05, p = 0.9728682170542635\n",
      "when eta = 0.045, p = 0.9806201550387597\n",
      "when eta = 0.04, p = 0.9883720930232558\n",
      "when eta = 0.025, p = 0.9883720930232558\n",
      "when eta = 0.0075, p = 0.9806201550387597\n",
      "when eta = 0.0025, p = 0.9457364341085271\n",
      "when eta = 0.00025, p = 0.7441860465116279\n"
     ]
    }
   ],
   "source": [
    "etas = [0.25, 0.075, 0.065, 0.06, 0.05, 0.045, 0.04, 0.025, 0.0075, 0.0025, 0.00025]\n",
    "for eta in etas:\n",
    "    w = (-1 + 2*np.random.random(100))/10\n",
    "    b = (-1 + 2*np.random.random())/10\n",
    "    i = 0\n",
    "    train_data = pd.read_csv(\"train_data.csv\")\n",
    "    for i in range(10000):\n",
    "        x = train_data.sample().values\n",
    "        y = x[0][100]\n",
    "        x = x[0][:100]\n",
    "        y_hat = liner(w, b, x.T)\n",
    "        w, b = optimize(w, b, eta, y_hat, y)\n",
    "    test_data = pd.read_csv(\"test_data.csv\")\n",
    "    cnt = 0\n",
    "    for i in range(258):\n",
    "        x = test_data.loc[i].values[:100]\n",
    "        y = test_data.loc[i].values[100]\n",
    "        y_hat = liner(w, b, x)\n",
    "        if(y_hat>0.5 and y==1):\n",
    "            cnt = cnt + 1\n",
    "        elif(y_hat<0.5 and y==0):\n",
    "            cnt = cnt + 1\n",
    "    p = cnt/258\n",
    "    print(\"when eta = {}, p = {}\".format(eta, p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
